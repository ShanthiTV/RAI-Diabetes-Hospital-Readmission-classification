{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#conda install azure-common azure-ai-ml==0.1.0b7 mltable==0.1.0b4 azureml_dataprep azureml_dataprep_rslex responsibleai raiwidgets pandas pyarrow shap "
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351303755
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1675351304829
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from raiwidgets import ResponsibleAIDashboard\n",
        "from responsibleai import RAIInsights\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1675351310556
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.entities import Environment, BuildContext\n",
        "from azureml.mlflow import register_model\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "\n",
        "#connect to the workspace\n",
        "registry_name = \"azureml\"\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client =  MLClient.from_config(credential=credential)\n",
        "\n",
        "ml_client_registry = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group_name=ml_client.resource_group_name,\n",
        "    registry_name=registry_name\n",
        "    )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: ./config.json\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1675351311418
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_name = \"trainingcompute\""
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351312007
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\r\n",
        "\r\n",
        "all_compute_names = [x.name for x in ml_client.compute.list()]\r\n",
        "\r\n",
        "if compute_name in all_compute_names:\r\n",
        "    print(f\"Found existing compute: {compute_name}\")\r\n",
        "else:\r\n",
        "    my_compute = AmlCompute(\r\n",
        "        name=compute_name,\r\n",
        "        size=\"Standard_DS2_v2\",\r\n",
        "        min_instances=0,\r\n",
        "        max_instances=4,\r\n",
        "        idle_time_before_scale_down=3600\r\n",
        "    )\r\n",
        "    ml_client.compute.begin_create_or_update(my_compute)\r\n",
        "    print(\"Initiated compute creation\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute: trainingcompute\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351312524
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rai_hospital_classifier_version_string = '124'\r\n",
        "version='1'"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351312865
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_df = pd.read_csv('data/diabetes-hospital-stay-dataset.csv')\r\n",
        "#ata_df.to_parquet('data/diabetes-hospital-stay-dataset.parquet')"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351313288
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#display(data_df)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351313550
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Employee count as all values are 1 and hence attrition is independent of this feature\r\n",
        "#data_df = data_df.drop(['EmployeeCount'], axis=1)\r\n",
        "# Dropping Employee Number since it is merely an identifier\r\n",
        "#data_df = data_df.drop(['EmployeeNumber'], axis=1)\r\n",
        "#data_df = data_df.drop(['Over18'], axis=1)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#data_df = data_df.drop(['CoapplicantIncome', 'Property_Area'], axis=1)\r\n",
        "\r\n",
        "# try removing irrelevant features\r\n",
        "\r\n",
        "\r\n",
        "# Changing target values to a more meaningful words\r\n",
        "#target_map = {0: 'Not readmitted', 1: 'Readmitted'}\r\n",
        "#data_df[\"readmit_status\"] = data_df[\"readmit_status\"].apply(lambda x: target_map[x])\r\n",
        "\r\n",
        "#target_column = \"readmit_less_than_30_days\"\r\n",
        "#target_column = \"readmit_status\""
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351313800
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train, test = train_test_split(data_df, test_size=0.2, random_state=1)\r\n",
        "\r\n",
        "#train_data = train.to_parquet('data/train_dataset.parquet')\r\n",
        "#test_data = test.to_parquet('data/test_dataset.parquet')"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351314081
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#source_data_path = 'data/diabetes-hospital-stay-dataset.csv'\r\n",
        "#all_emp_data_parquet = data_df.to_parquet(source_data_path)\r\n"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351338553
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_parquet('data/train_dataset.parquet')\r\n",
        "test_data = pd.read_parquet('data/test_dataset.parquet')"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351366540
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing target values to a more meaningful words\r\n",
        "train_data['readmit_status'] = train_data['readmit_status'].replace({0:\"Not readmitted\", 1:\"Readmitted\"})\r\n",
        "test_data['readmit_status'] = test_data['readmit_status'].replace({0:\"Not readmitted\", 1:\"Readmitted\"})\r\n",
        "#data_df['readmit_status'] = data_df['readmit_status'].replace({0:\"Not readmitted\", 1:\"Readmitted\"})\r\n",
        "\r\n",
        "target_column = \"readmit_status\""
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351393433
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(test_data)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                 race  gender            age discharge_destination  \\\n3604        Caucasian  Female  Over 60 years    Discharged to Home   \n1322        Caucasian    Male  Over 60 years    Discharged to Home   \n1227        Caucasian  Female  Over 60 years                 Other   \n4151  AfricanAmerican    Male  Over 60 years                 Other   \n742         Caucasian  Female    30-60 years    Discharged to Home   \n...               ...     ...            ...                   ...   \n3008        Caucasian  Female    30-60 years                 Other   \n2570  AfricanAmerican  Female    30-60 years    Discharged to Home   \n2484  AfricanAmerican  Female  Over 60 years    Discharged to Home   \n2337  AfricanAmerican  Female    30-60 years    Discharged to Home   \n200         Caucasian  Female  Over 60 years                 Other   \n\n      admission_source  time_in_hospital  num_lab_procedures  num_procedures  \\\n3604                 7                 3                  27               0   \n1322                 7                 3                  61               0   \n1227                 7                 5                  48               0   \n4151                 4                 3                  43               0   \n742                  7                 2                  56               0   \n...                ...               ...                 ...             ...   \n3008                 1                 7                  48               1   \n2570                 7                 4                  54               0   \n2484                 1                 1                  46               0   \n2337                 7                 2                  54               1   \n200                  7                 7                  56               0   \n\n      num_medications  prior_outpatient  ...  prior_inpatient  \\\n3604               12                 1  ...                0   \n1322                8                 0  ...                0   \n1227               17                 0  ...                0   \n4151                7                 0  ...                0   \n742                10                 0  ...                0   \n...               ...               ...  ...              ...   \n3008               16                 4  ...                6   \n2570               14                 0  ...                0   \n2484                5                 0  ...                0   \n2337               14                 0  ...                4   \n200                11                 0  ...                1   \n\n      primary_diagnosis  number_diagnoses  max_glu_serum A1Cresult insulin  \\\n3604                0.0                 9           None      None  Steady   \n1322                0.0                 6           None        >8  Steady   \n1227                0.0                 9           None      None      No   \n4151                0.0                 9           None      None  Steady   \n742                 0.0                 9           None      None      No   \n...                 ...               ...            ...       ...     ...   \n3008                0.0                 8           None      None      No   \n2570                0.0                 9           None      None      Up   \n2484                0.0                 3           None        >8  Steady   \n2337                0.0                 4           None      None      Up   \n200                 0.0                 9           None      None      No   \n\n     diabetes_Med_prescribe  readmit_status medicare  medicaid  \n3604                    Yes  Not readmitted     True     False  \n1322                    Yes  Not readmitted    False     False  \n1227                     No      Readmitted    False     False  \n4151                    Yes      Readmitted    False     False  \n742                      No  Not readmitted     True     False  \n...                     ...             ...      ...       ...  \n3008                     No      Readmitted     True     False  \n2570                    Yes  Not readmitted    False     False  \n2484                    Yes  Not readmitted    False     False  \n2337                    Yes      Readmitted    False     False  \n200                      No  Not readmitted     True     False  \n\n[994 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>race</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>discharge_destination</th>\n      <th>admission_source</th>\n      <th>time_in_hospital</th>\n      <th>num_lab_procedures</th>\n      <th>num_procedures</th>\n      <th>num_medications</th>\n      <th>prior_outpatient</th>\n      <th>...</th>\n      <th>prior_inpatient</th>\n      <th>primary_diagnosis</th>\n      <th>number_diagnoses</th>\n      <th>max_glu_serum</th>\n      <th>A1Cresult</th>\n      <th>insulin</th>\n      <th>diabetes_Med_prescribe</th>\n      <th>readmit_status</th>\n      <th>medicare</th>\n      <th>medicaid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3604</th>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>7</td>\n      <td>3</td>\n      <td>27</td>\n      <td>0</td>\n      <td>12</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Steady</td>\n      <td>Yes</td>\n      <td>Not readmitted</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1322</th>\n      <td>Caucasian</td>\n      <td>Male</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>7</td>\n      <td>3</td>\n      <td>61</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>6</td>\n      <td>None</td>\n      <td>&gt;8</td>\n      <td>Steady</td>\n      <td>Yes</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1227</th>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>Over 60 years</td>\n      <td>Other</td>\n      <td>7</td>\n      <td>5</td>\n      <td>48</td>\n      <td>0</td>\n      <td>17</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4151</th>\n      <td>AfricanAmerican</td>\n      <td>Male</td>\n      <td>Over 60 years</td>\n      <td>Other</td>\n      <td>4</td>\n      <td>3</td>\n      <td>43</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Steady</td>\n      <td>Yes</td>\n      <td>Readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>742</th>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>30-60 years</td>\n      <td>Discharged to Home</td>\n      <td>7</td>\n      <td>2</td>\n      <td>56</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Not readmitted</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3008</th>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>30-60 years</td>\n      <td>Other</td>\n      <td>1</td>\n      <td>7</td>\n      <td>48</td>\n      <td>1</td>\n      <td>16</td>\n      <td>4</td>\n      <td>...</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>8</td>\n      <td>None</td>\n      <td>None</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Readmitted</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2570</th>\n      <td>AfricanAmerican</td>\n      <td>Female</td>\n      <td>30-60 years</td>\n      <td>Discharged to Home</td>\n      <td>7</td>\n      <td>4</td>\n      <td>54</td>\n      <td>0</td>\n      <td>14</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Up</td>\n      <td>Yes</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2484</th>\n      <td>AfricanAmerican</td>\n      <td>Female</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>1</td>\n      <td>1</td>\n      <td>46</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>None</td>\n      <td>&gt;8</td>\n      <td>Steady</td>\n      <td>Yes</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2337</th>\n      <td>AfricanAmerican</td>\n      <td>Female</td>\n      <td>30-60 years</td>\n      <td>Discharged to Home</td>\n      <td>7</td>\n      <td>2</td>\n      <td>54</td>\n      <td>1</td>\n      <td>14</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Up</td>\n      <td>Yes</td>\n      <td>Readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>200</th>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>Over 60 years</td>\n      <td>Other</td>\n      <td>7</td>\n      <td>7</td>\n      <td>56</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Not readmitted</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>994 rows × 21 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351425526
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[target_column].value_counts())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Not readmitted    3280\nReadmitted         696\nName: readmit_status, dtype: int64\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351440669
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[target_column].value_counts())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Not readmitted    811\nReadmitted        183\nName: readmit_status, dtype: int64\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351474753
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "           race  gender            age discharge_destination  \\\n3572  Caucasian    Male  Over 60 years                 Other   \n543   Caucasian    Male  Over 60 years    Discharged to Home   \n2074  Caucasian  Female  Over 60 years    Discharged to Home   \n4190  Caucasian    Male    30-60 years    Discharged to Home   \n42     Hispanic  Female    30-60 years                 Other   \n\n      admission_source  time_in_hospital  num_lab_procedures  num_procedures  \\\n3572                 7                12                  85               2   \n543                  1                 3                  42               0   \n2074                 7                 7                  48               1   \n4190                 1                 4                  38               3   \n42                   7                 1                  50               0   \n\n      num_medications  prior_outpatient  ...  prior_inpatient  \\\n3572               21                 0  ...                0   \n543                17                 0  ...                1   \n2074               20                 0  ...                0   \n4190               18                 0  ...                0   \n42                  8                 0  ...                0   \n\n      primary_diagnosis  number_diagnoses  max_glu_serum A1Cresult insulin  \\\n3572                0.0                 9           None      Norm      Up   \n543                 0.0                 8           None      None  Steady   \n2074                0.0                 9           None      None      No   \n4190                0.0                 9           None      None    Down   \n42                  0.0                 9           None        >8      No   \n\n     diabetes_Med_prescribe  readmit_status medicare  medicaid  \n3572                    Yes  Not readmitted    False     False  \n543                     Yes  Not readmitted     True     False  \n2074                     No  Not readmitted     True     False  \n4190                    Yes      Readmitted    False      True  \n42                       No  Not readmitted    False     False  \n\n[5 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>race</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>discharge_destination</th>\n      <th>admission_source</th>\n      <th>time_in_hospital</th>\n      <th>num_lab_procedures</th>\n      <th>num_procedures</th>\n      <th>num_medications</th>\n      <th>prior_outpatient</th>\n      <th>...</th>\n      <th>prior_inpatient</th>\n      <th>primary_diagnosis</th>\n      <th>number_diagnoses</th>\n      <th>max_glu_serum</th>\n      <th>A1Cresult</th>\n      <th>insulin</th>\n      <th>diabetes_Med_prescribe</th>\n      <th>readmit_status</th>\n      <th>medicare</th>\n      <th>medicaid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3572</th>\n      <td>Caucasian</td>\n      <td>Male</td>\n      <td>Over 60 years</td>\n      <td>Other</td>\n      <td>7</td>\n      <td>12</td>\n      <td>85</td>\n      <td>2</td>\n      <td>21</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>None</td>\n      <td>Norm</td>\n      <td>Up</td>\n      <td>Yes</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>543</th>\n      <td>Caucasian</td>\n      <td>Male</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>1</td>\n      <td>3</td>\n      <td>42</td>\n      <td>0</td>\n      <td>17</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>8</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Steady</td>\n      <td>Yes</td>\n      <td>Not readmitted</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2074</th>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>7</td>\n      <td>7</td>\n      <td>48</td>\n      <td>1</td>\n      <td>20</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Not readmitted</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4190</th>\n      <td>Caucasian</td>\n      <td>Male</td>\n      <td>30-60 years</td>\n      <td>Discharged to Home</td>\n      <td>1</td>\n      <td>4</td>\n      <td>38</td>\n      <td>3</td>\n      <td>18</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Down</td>\n      <td>Yes</td>\n      <td>Readmitted</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>30-60 years</td>\n      <td>Other</td>\n      <td>7</td>\n      <td>1</td>\n      <td>50</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>9</td>\n      <td>None</td>\n      <td>&gt;8</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351506700
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "\r\n",
        "training_dataset_filename = 'hospital_train_parquet'\r\n",
        "testing_dataset_filename = 'hospital_test_parquet'\r\n",
        "\r\n",
        "\r\n",
        "training_data = Data(\r\n",
        "    name=training_dataset_filename,\r\n",
        "    path='data/train_dataset.parquet',\r\n",
        "    type=AssetTypes.URI_FILE,\r\n",
        "    description=\"RAI hospital  train data\",  \r\n",
        ")\r\n",
        "\r\n",
        "tr_data = ml_client.data.create_or_update(training_data)\r\n",
        "\r\n",
        "testing_data = Data(\r\n",
        "    name=testing_dataset_filename,\r\n",
        "    path='data/test_dataset.parquet',\r\n",
        "    type=AssetTypes.URI_FILE,\r\n",
        "    description=\"RAI hospital  test data\",  \r\n",
        ")\r\n",
        "\r\n",
        "te_data = ml_client.data.create_or_update(testing_data)\r\n"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351540496
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "os.makedirs('component', exist_ok=True)\r\n",
        "os.makedirs('register_model_src', exist_ok=True)\r\n",
        "os.makedirs('environment', exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351556512
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_docker_context = Environment(\r\n",
        "    build=BuildContext(path=\"environment\"),\r\n",
        "    name=\"aml_rai_environment\",\r\n",
        "    description=\"Environment created from a Docker context.\",\r\n",
        ")\r\n",
        "ml_client.environments.create_or_update(env_docker_context)\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "Environment({'is_anonymous': False, 'auto_increment_version': False, 'name': 'aml_rai_environment', 'description': 'Environment created from a Docker context.', 'tags': {}, 'properties': {}, 'id': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/demoRG/providers/Microsoft.MachineLearningServices/workspaces/aml-ws/environments/aml_rai_environment/versions/25', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/trainingcompute/code/Users/ruyakubu/responsibleaidashboard-loan-approval-model-classification', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fb1213ded00>, 'serialize': <msrest.serialization.Serializer object at 0x7fb1213debb0>, 'version': '25', 'latest_version': None, 'conda_file': None, 'image': None, 'build': <azure.ai.ml.entities._assets.environment.BuildContext object at 0x7fb1213ded90>, 'inference_config': None, 'os_type': 'Linux', 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351589254
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile component/hospital_training.py\r\n",
        "\r\n",
        "\r\n",
        "from pathlib import Path\r\n",
        "import sys\r\n",
        "import os\r\n",
        "\r\n",
        "parent_dir =  os.path.dirname(os.getcwd())\r\n",
        " \r\n",
        "# setting path\r\n",
        "sys.path.append(parent_dir)\r\n",
        "\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import tempfile\r\n",
        "\r\n",
        "from azureml.core import Run\r\n",
        "\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.compose import make_column_selector as selector\r\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "    # setup arg parser\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "\r\n",
        "    # add arguments\r\n",
        "    parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\r\n",
        "    parser.add_argument(\"--target_column_name\", type=str, help=\"Name of target column\")\r\n",
        "    parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parser.parse_args()    \r\n",
        "\r\n",
        "    # return args\r\n",
        "    return args\r\n",
        "\r\n",
        "def get_categorical_index(categorical_fields):\r\n",
        "    cat_idx = []\r\n",
        "    for col, value in categorical_fields.iteritems():\r\n",
        "        if value.dtype == 'object':\r\n",
        "            cat_idx.append(categorical_fields.columns.get_loc(col))\r\n",
        "    print(\"col indices: \", cat_idx)  \r\n",
        "    return cat_idx    \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def main(args):\r\n",
        "    current_experiment = Run.get_context().experiment\r\n",
        "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\r\n",
        "    print(\"tracking_uri: {0}\".format(tracking_uri))\r\n",
        "    mlflow.set_tracking_uri(tracking_uri)\r\n",
        "    mlflow.set_experiment(current_experiment.name)\r\n",
        "\r\n",
        "    # Read in data\r\n",
        "    print(\"Reading data\")\r\n",
        "    all_training_data = pd.read_parquet(args.training_data)\r\n",
        "    target = all_training_data[args.target_column_name]\r\n",
        "    features = all_training_data.drop([args.target_column_name], axis = 1)  \r\n",
        "\r\n",
        "    #features['age'] = pd.Categorical(all_training_data['age'], categories=['30 years or younger', '30-60 years', 'Over 60 years'], ordered=True)\r\n",
        "\r\n",
        "    # Transform string data to numeric\r\n",
        "    numerical_selector = selector(dtype_include=np.number)\r\n",
        "    categorical_selector = selector(dtype_exclude=np.number)\r\n",
        "\r\n",
        "    numerical_columns = numerical_selector(features)\r\n",
        "    categorical_columns = categorical_selector(features)\r\n",
        "\r\n",
        "    categorial_encoder = OneHotEncoder(handle_unknown=\"ignore\")\r\n",
        "    numerical_encoder = StandardScaler()\r\n",
        "\r\n",
        "    preprocessor = ColumnTransformer([\r\n",
        "    ('categorical-encoder', categorial_encoder, categorical_columns),\r\n",
        "    ('standard_scaler', numerical_encoder, numerical_columns)])\r\n",
        "\r\n",
        "    categorical_indices = get_categorical_index(features)\r\n",
        "    #clf = make_pipeline(preprocessor, RandomForestClassifier())\r\n",
        "    clf = make_pipeline(preprocessor, LogisticRegression())\r\n",
        "    \r\n",
        "\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=1)\r\n",
        "\r\n",
        "    print(\"Training model...\") \r\n",
        "    \r\n",
        "    model = clf.fit(X_train, y_train)\r\n",
        " \r\n",
        "    # Saving model with mlflow - leave this section unchanged\r\n",
        "    model_dir =  \"./model_output\"\r\n",
        "    with tempfile.TemporaryDirectory() as td:\r\n",
        "        print(\"Saving model with MLFlow to temporary directory\")\r\n",
        "        tmp_output_dir = os.path.join(td, model_dir)\r\n",
        "        mlflow.sklearn.save_model(sk_model=model, path=tmp_output_dir)\r\n",
        "\r\n",
        "        print(\"Copying MLFlow model to output path\")\r\n",
        "        for file_name in os.listdir(tmp_output_dir):\r\n",
        "            print(\"  Copying: \", file_name)\r\n",
        "            # As of Python 3.8, copytree will acquire dirs_exist_ok as\r\n",
        "            # an option, removing the need for listdir\r\n",
        "            shutil.copy2(src=os.path.join(tmp_output_dir, file_name), dst=os.path.join(args.model_output, file_name))\r\n",
        "\r\n",
        "\r\n",
        "# run script\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parse_args()\r\n",
        "\r\n",
        "    # run main function\r\n",
        "    main(args)\r\n",
        "\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting component/hospital_training.py\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile register_model_src/model_register.py\r\n",
        "\r\n",
        "# ---------------------------------------------------------\r\n",
        "# Copyright (c) Microsoft Corporation. All rights reserved.\r\n",
        "# ---------------------------------------------------------\r\n",
        "\r\n",
        "import argparse\r\n",
        "import json\r\n",
        "import os\r\n",
        "import time\r\n",
        "\r\n",
        "\r\n",
        "from azureml.core import Run\r\n",
        "\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "\r\n",
        "# Based on example:\r\n",
        "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-cli\r\n",
        "# which references\r\n",
        "# https://github.com/Azure/azureml-examples/tree/main/cli/jobs/train/lightgbm/iris\r\n",
        "\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "    # setup arg parser\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "\r\n",
        "    # add arguments\r\n",
        "    parser.add_argument(\"--model_input_path\", type=str, help=\"Path to input model\")\r\n",
        "    parser.add_argument(\r\n",
        "        \"--model_info_output_path\", type=str, help=\"Path to write model info JSON\"\r\n",
        "    )\r\n",
        "    parser.add_argument(\r\n",
        "        \"--model_base_name\", type=str, help=\"Name of the registered model\"\r\n",
        "    )\r\n",
        "    parser.add_argument(\r\n",
        "        \"--model_name_suffix\", type=int, help=\"Set negative to use epoch_secs\"\r\n",
        "    )\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parser.parse_args()\r\n",
        "\r\n",
        "    # return args\r\n",
        "    return args\r\n",
        "\r\n",
        "\r\n",
        "def main(args):\r\n",
        "    current_experiment = Run.get_context().experiment\r\n",
        "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\r\n",
        "    print(\"tracking_uri: {0}\".format(tracking_uri))\r\n",
        "    mlflow.set_tracking_uri(tracking_uri)\r\n",
        "    mlflow.set_experiment(current_experiment.name)\r\n",
        "\r\n",
        "    print(\"Loading model\")\r\n",
        "    mlflow_model = mlflow.sklearn.load_model(args.model_input_path)\r\n",
        "\r\n",
        "    if args.model_name_suffix < 0:\r\n",
        "        suffix = int(time.time())\r\n",
        "    else:\r\n",
        "        suffix = args.model_name_suffix\r\n",
        "    registered_name = \"{0}_{1}\".format(args.model_base_name, suffix)\r\n",
        "    print(f\"Registering model as {registered_name}\")\r\n",
        "\r\n",
        "    print(\"Registering via MLFlow\")\r\n",
        "    mlflow.sklearn.log_model(\r\n",
        "        sk_model=mlflow_model,\r\n",
        "        registered_model_name=registered_name,\r\n",
        "        artifact_path=registered_name,\r\n",
        "    )\r\n",
        "\r\n",
        "    print(\"Writing JSON\")\r\n",
        "    dict = {\"id\": \"{0}:1\".format(registered_name)}\r\n",
        "    output_path = os.path.join(args.model_info_output_path, \"model_info.json\")\r\n",
        "    with open(output_path, \"w\") as of:\r\n",
        "        json.dump(dict, fp=of)\r\n",
        "\r\n",
        "\r\n",
        "# run script\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parse_args()\r\n",
        "\r\n",
        "    # run main function\r\n",
        "    main(args)\r\n",
        "\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting register_model_src/model_register.py\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "\n",
        "yaml_contents = f\"\"\"\n",
        "$schema: http://azureml/sdk-2-0/CommandComponent.json\n",
        "name: rai_hospital_training_component\n",
        "display_name: hospital  classification training component for RAI example\n",
        "version: {rai_hospital_classifier_version_string}\n",
        "type: command\n",
        "inputs:\n",
        "  training_data:\n",
        "    type: path\n",
        "  target_column_name:\n",
        "    type: string\n",
        "outputs:\n",
        "  model_output:\n",
        "    type: path\n",
        "code: ./component/\n",
        "environment: azureml:aml_rai_environment@latest\n",
        "\"\"\" + r\"\"\"\n",
        "command: >-\n",
        "  python hospital_training.py\n",
        "  --training_data ${{{{inputs.training_data}}}}\n",
        "  --target_column_name ${{{{inputs.target_column_name}}}}\n",
        "  --model_output ${{{{outputs.model_output}}}}\n",
        "\"\"\"\n",
        "\n",
        "yaml_filename = \"RAIhospitalClassificationTrainingComponent.yaml\"\n",
        "\n",
        "with open(yaml_filename, 'w') as f:\n",
        "    f.write(yaml_contents.format(yaml_contents))\n",
        "    \n",
        "train_component_definition = load_component(\n",
        "    source=yaml_filename\n",
        ")\n",
        "\n",
        "ml_client.components.create_or_update(train_component_definition)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "CommandComponent({'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'name': 'rai_hospital_training_component', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/demoRG/providers/Microsoft.MachineLearningServices/workspaces/aml-ws/components/rai_hospital_training_component/versions/124', 'Resource__source_path': None, 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7fb120064370>, 'serialize': <msrest.serialization.Serializer object at 0x7fb120060a60>, 'command': 'python hospital_training.py --training_data ${{inputs.training_data}} --target_column_name ${{inputs.target_column_name}} --model_output ${{outputs.model_output}}', 'code': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/demoRG/providers/Microsoft.MachineLearningServices/workspaces/aml-ws/codes/b1f822d6-2eaf-4fbb-a0d6-ebba570fb592/versions/1', 'environment_variables': None, 'environment': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/demoRG/providers/Microsoft.MachineLearningServices/workspaces/aml-ws/environments/aml_rai_environment/versions/25', 'distribution': None, 'resources': {'instance_count': 1, 'properties': {}}, 'version': '124', 'latest_version': None, 'schema': 'http://azureml/sdk-2-0/CommandComponent.json', 'type': 'command', 'display_name': 'hospital  classification training component for RAI example', 'is_deterministic': True, 'inputs': {'training_data': {'type': 'path'}, 'target_column_name': {'type': 'string'}}, 'outputs': {'model_output': {'type': 'path'}}, 'yaml_str': None, 'other_parameter': {}, 'func': <function [component] hospital  classification training component for RAI example at 0x7fb12009a280>})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1675351782668
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_contents = f\"\"\"\r\n",
        "$schema: http://azureml/sdk-2-0/CommandComponent.json\r\n",
        "name: register_hospital_model\r\n",
        "display_name: Register hospital Model\r\n",
        "version: {rai_hospital_classifier_version_string}\r\n",
        "type: command\r\n",
        "is_deterministic: False\r\n",
        "inputs:\r\n",
        "  model_input_path:\r\n",
        "    type: path\r\n",
        "  model_base_name:\r\n",
        "    type: string\r\n",
        "  model_name_suffix: # Set negative to use epoch_secs\r\n",
        "    type: integer\r\n",
        "    default: -1\r\n",
        "outputs:\r\n",
        "  model_info_output_path:\r\n",
        "    type: path\r\n",
        "code: ./register_model_src/\r\n",
        "environment: azureml://registries/azureml/environments/AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu/versions/4\r\n",
        "command: >-\r\n",
        "  python model_register.py\r\n",
        "  --model_input_path ${{{{inputs.model_input_path}}}}\r\n",
        "  --model_base_name ${{{{inputs.model_base_name}}}}\r\n",
        "  --model_name_suffix ${{{{inputs.model_name_suffix}}}}\r\n",
        "  --model_info_output_path ${{{{outputs.model_info_output_path}}}}\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "yaml_filename = \"model_register.yaml\"\r\n",
        "\r\n",
        "with open(yaml_filename, 'w') as f:\r\n",
        "    f.write(yaml_contents)\r\n",
        "    \r\n",
        "register_component = load_component(\r\n",
        "    source=yaml_filename\r\n",
        ")\r\n",
        "\r\n",
        "ml_client.components.create_or_update(register_component)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "CommandComponent({'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'name': 'register_hospital_model', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/demoRG/providers/Microsoft.MachineLearningServices/workspaces/aml-ws/components/register_hospital_model/versions/124', 'Resource__source_path': None, 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7fb10efe6bb0>, 'serialize': <msrest.serialization.Serializer object at 0x7fb120064670>, 'command': 'python model_register.py --model_input_path ${{inputs.model_input_path}} --model_base_name ${{inputs.model_base_name}} --model_name_suffix ${{inputs.model_name_suffix}} --model_info_output_path ${{outputs.model_info_output_path}}', 'code': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/demoRG/providers/Microsoft.MachineLearningServices/workspaces/aml-ws/codes/8453ff98-e386-4fe1-9177-9133162c5bc4/versions/1', 'environment_variables': None, 'environment': 'azureml://registries/azureml/environments/AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu/versions/4', 'distribution': None, 'resources': {'instance_count': 1, 'properties': {}}, 'version': '124', 'latest_version': None, 'schema': 'http://azureml/sdk-2-0/CommandComponent.json', 'type': 'command', 'display_name': 'Register hospital Model', 'is_deterministic': False, 'inputs': {'model_input_path': {'type': 'path'}, 'model_base_name': {'type': 'string'}, 'model_name_suffix': {'type': 'integer', 'default': -1}}, 'outputs': {'model_info_output_path': {'type': 'path'}}, 'yaml_str': None, 'other_parameter': {}, 'func': <function [component] Register hospital Model at 0x7fb121ca39d0>})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351784560
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\r\n",
        "\r\n",
        "model_name_suffix = int(time.time())\r\n",
        "model_base_name = 'rai_hospital_model'"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351785031
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl, Input\r\n",
        "\r\n",
        "\r\n",
        "hospital_train_parquet = Input(\r\n",
        "    type=\"uri_file\", path=\"data/train_dataset.parquet\", mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "hospital_test_parquet = Input(\r\n",
        "    type=\"uri_file\", path=\"data/test_dataset.parquet\", mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "@dsl.pipeline(\r\n",
        "    compute=compute_name,\r\n",
        "    description=\"Register Model for RAI hospital \",\r\n",
        "    experiment_name=f\"RAI_hospital_Model_Training_{model_name_suffix}\",\r\n",
        ")\r\n",
        "def my_training_pipeline(target_column_name, training_data):\r\n",
        "    trained_model = train_component_definition(\r\n",
        "        target_column_name=target_column_name,\r\n",
        "        training_data=training_data\r\n",
        "    )\r\n",
        "    trained_model.set_limits(timeout=120)\r\n",
        "\r\n",
        "    _ = register_component(\r\n",
        "        model_input_path=trained_model.outputs.model_output,\r\n",
        "        model_base_name=model_base_name,\r\n",
        "        model_name_suffix=model_name_suffix,\r\n",
        "    )\r\n",
        "\r\n",
        "    return {}\r\n",
        "\r\n",
        "model_registration_pipeline_job = my_training_pipeline(target_column, hospital_train_parquet)"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351785400
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import PipelineJob\r\n",
        "import webbrowser\r\n",
        "\r\n",
        "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\r\n",
        "    created_job = ml_client.jobs.create_or_update(pipeline_job)\r\n",
        "    assert created_job is not None\r\n",
        "\r\n",
        "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\r\n",
        "        time.sleep(30)\r\n",
        "        created_job = ml_client.jobs.get(created_job.name)\r\n",
        "        print(\"Latest status : {0}\".format(created_job.status))\r\n",
        "\r\n",
        "\r\n",
        "    # open the pipeline in web browser\r\n",
        "    webbrowser.open(created_job.services[\"Studio\"].endpoint)\r\n",
        "    \r\n",
        "    #assert created_job.status == 'Completed'\r\n",
        "    return created_job\r\n",
        "\r\n",
        "# This is the actual submission\r\n",
        "training_job = submit_and_wait(ml_client, model_registration_pipeline_job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Latest status : Running\nLatest status : Completed\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351849057
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expected_model_id = f'{model_base_name}_{model_name_suffix}:1'\r\n",
        "azureml_model_id = f'azureml:{expected_model_id}'"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351849681
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_categorical_numerical_data(dataset):\r\n",
        "    dataset = dataset.drop([target_column], axis = 1)  \r\n",
        "    categorical = []\r\n",
        "    for col, value in dataset.iteritems():\r\n",
        "        if value.dtype == 'object' or value.dtype == 'bool':\r\n",
        "            categorical.append(col)\r\n",
        "    numerical = dataset.columns.difference(categorical)\r\n",
        "    return categorical, numerical"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351850282
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get categorical and numerical fields from training data\r\n",
        "categorical, numerical = get_categorical_numerical_data(train_data)\r\n",
        "print(\"categorical columns: \",  categorical)\r\n",
        "print(\"numerical field: \", numerical)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "categorical columns:  ['race', 'gender', 'age', 'discharge_destination', 'max_glu_serum', 'A1Cresult', 'insulin', 'diabetes_Med_prescribe', 'medicare', 'medicaid']\nnumerical field:  Index(['admission_source', 'num_lab_procedures', 'num_medications',\n       'num_procedures', 'number_diagnoses', 'primary_diagnosis',\n       'prior_emergency', 'prior_inpatient', 'prior_outpatient',\n       'time_in_hospital'],\n      dtype='object')\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351850939
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = \"latest\"\r\n",
        "\r\n",
        "rai_constructor_component = ml_client_registry.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=label\r\n",
        ")\r\n",
        "\r\n",
        "# We get latest version and use the same version for all components\r\n",
        "version = rai_constructor_component.version\r\n",
        "\r\n",
        "rai_counterfactual_component = ml_client_registry.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_counterfactual\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_causal_component = ml_client_registry.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_causal\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_explanation_component = ml_client_registry.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_explanation\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_erroranalysis_component = ml_client_registry.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_erroranalysis\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_gather_component = ml_client_registry.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_gather\", version=version\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351851578
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "@dsl.pipeline(\r\n",
        "        compute=compute_name,\r\n",
        "        description=\"RAI computation on hospital readmit classification data\",\r\n",
        "        experiment_name=f\"RAI_hospital_Classification_RAIInsights_Computation_{model_name_suffix}\",\r\n",
        "    )\r\n",
        "def rai_classification_pipeline(\r\n",
        "        target_column_name,\r\n",
        "        training_data,\r\n",
        "        testing_data\r\n",
        "    ):\r\n",
        "        \r\n",
        "        # Initiate the RAIInsights\r\n",
        "        create_rai_job = rai_constructor_component(\r\n",
        "            title=\"RAI Dashboard\",\r\n",
        "            task_type=\"classification\",\r\n",
        "            model_info=expected_model_id,\r\n",
        "            model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),            \r\n",
        "            train_dataset=training_data,\r\n",
        "            test_dataset=testing_data,\r\n",
        "            target_column_name=target_column_name,\r\n",
        "            #classes=json.dumps(['not readmitted', 'readmitted']),\r\n",
        "            categorical_column_names=json.dumps(categorical),\r\n",
        "        )\r\n",
        "        create_rai_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "        # Add an explanation\r\n",
        "        explain_job = rai_explanation_component(\r\n",
        "            comment=\"Explanation for hospital remitted less than 30days  classification\",\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        explain_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "        # Add error analysis\r\n",
        "        erroranalysis_job = rai_erroranalysis_component(\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        erroranalysis_job.set_limits(timeout=120)\r\n",
        "\r\n",
        "        # Add counterfactual analysis\r\n",
        "        counterfactual_job = rai_counterfactual_component(\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "            total_cfs=10,\r\n",
        "            desired_class='opposite',\r\n",
        "        )\r\n",
        "        counterfactual_job.set_limits(timeout=600)\r\n",
        "\r\n",
        "        # Add causal analysis\r\n",
        "        causal_job = rai_causal_component(\r\n",
        "            treatment_features=json.dumps(['time_in_hospital']),\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        causal_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "\r\n",
        "        # Combine everything\r\n",
        "        rai_gather_job = rai_gather_component(\r\n",
        "            constructor=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "            insight_1=explain_job.outputs.explanation,\r\n",
        "            insight_2=causal_job.outputs.causal,\r\n",
        "            insight_3=counterfactual_job.outputs.counterfactual,\r\n",
        "            insight_4=erroranalysis_job.outputs.error_analysis,\r\n",
        "        )\r\n",
        "        rai_gather_job.set_limits(timeout=120)\r\n",
        "\r\n",
        "        rai_gather_job.outputs.dashboard.mode = \"upload\"\r\n",
        "        rai_gather_job.outputs.ux_json.mode = \"upload\"\r\n",
        "\r\n",
        "        return {\r\n",
        "            \"dashboard\": rai_gather_job.outputs.dashboard,\r\n",
        "            \"ux_json\": rai_gather_job.outputs.ux_json\r\n",
        "        }"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675351852172
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\r\n",
        "from azure.ai.ml import Output\r\n",
        "\r\n",
        "# Pipeline to construct the RAI Insights\r\n",
        "insights_pipeline_job = rai_classification_pipeline(\r\n",
        "    target_column_name=target_column,\r\n",
        "    training_data=hospital_train_parquet,\r\n",
        "    testing_data=hospital_test_parquet,\r\n",
        ")\r\n",
        "\r\n",
        "# Workaround to enable the download\r\n",
        "rand_path = str(uuid.uuid4())\r\n",
        "insights_pipeline_job.outputs.dashboard = Output(\r\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\r\n",
        "    mode=\"upload\",\r\n",
        "    type=\"uri_folder\",\r\n",
        ")\r\n",
        "insights_pipeline_job.outputs.ux_json = Output(\r\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/ux_json/\",\r\n",
        "    mode=\"upload\",\r\n",
        "    type=\"uri_folder\",\r\n",
        "\r\n",
        ")\r\n",
        "\r\n",
        "# submit pipeline\r\n",
        "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Latest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Completed\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675352307083
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_id = ml_client._operation_scope.subscription_id\r\n",
        "rg_name = ml_client._operation_scope.resource_group_name\r\n",
        "ws_name = ml_client.workspace_name\r\n",
        "\r\n",
        "expected_uri = f\"https://ml.azure.com/model/{expected_model_id}/model_analysis?wsid=/subscriptions/{sub_id}/resourcegroups/{rg_name}/workspaces/{ws_name}\"\r\n",
        "\r\n",
        "print(f\"Please visit {expected_uri} to see your analysis\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Please visit https://ml.azure.com/model/rai_hospital_model_1675351783:1/model_analysis?wsid=/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourcegroups/demoRG/workspaces/aml-ws to see your analysis\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675352307514
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}