{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#conda install azure-common azure-ai-ml==0.1.0b7 mltable==0.1.0b4 azureml_dataprep azureml_dataprep_rslex responsibleai raiwidgets pandas pyarrow shap "
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636024493
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1675636024995
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from raiwidgets import ResponsibleAIDashboard\n",
        "from responsibleai import RAIInsights\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1675636030101
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.entities import Environment, BuildContext\n",
        "from azureml.mlflow import register_model\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "\n",
        "#connect to the workspace\n",
        "registry_name = \"azureml\"\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client =  MLClient.from_config(credential=credential)\n",
        "\n",
        "ml_client_registry = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=ml_client.subscription_id,\n",
        "    resource_group_name=ml_client.resource_group_name,\n",
        "    registry_name=registry_name\n",
        "    )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: ./config.json\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1675636032211
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_name = \"trainingcompute\""
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636032874
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import AmlCompute\r\n",
        "\r\n",
        "all_compute_names = [x.name for x in ml_client.compute.list()]\r\n",
        "\r\n",
        "if compute_name in all_compute_names:\r\n",
        "    print(f\"Found existing compute: {compute_name}\")\r\n",
        "else:\r\n",
        "    my_compute = AmlCompute(\r\n",
        "        name=compute_name,\r\n",
        "        size=\"Standard_DS2_v2\",\r\n",
        "        min_instances=0,\r\n",
        "        max_instances=4,\r\n",
        "        idle_time_before_scale_down=3600\r\n",
        "    )\r\n",
        "    ml_client.compute.begin_create_or_update(my_compute)\r\n",
        "    print(\"Initiated compute creation\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute: trainingcompute\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636033296
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rai_hospital_classifier_version_string = '134'\r\n",
        "version='1'"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636033688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_parquet('data/train_dataset.parquet')\r\n",
        "test_data = pd.read_parquet('data/test_dataset.parquet')"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636035319
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_column = \"readmit_status\""
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636035778
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(train_data)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                 race  gender            age discharge_destination  \\\n1621        Caucasian  Female  Over 60 years    Discharged to Home   \n902   AfricanAmerican    Male  Over 60 years    Discharged to Home   \n3728        Caucasian    Male  Over 60 years                 Other   \n701         Caucasian  Female  Over 60 years                 Other   \n3776        Caucasian  Female  Over 60 years                 Other   \n...               ...     ...            ...                   ...   \n2895        Caucasian    Male  Over 60 years    Discharged to Home   \n2763        Caucasian    Male  Over 60 years    Discharged to Home   \n905   AfricanAmerican  Female  Over 60 years    Discharged to Home   \n3980        Caucasian  Female  Over 60 years    Discharged to Home   \n235         Caucasian    Male  Over 60 years    Discharged to Home   \n\n      admission_source  time_in_hospital  num_lab_procedures  num_procedures  \\\n1621                 7                 5                  40               0   \n902                  7                 2                  35               0   \n3728                 7                 3                  46               0   \n701                  7                 9                  53               2   \n3776                 1                 9                  82               3   \n...                ...               ...                 ...             ...   \n2895                 1                 2                  20               1   \n2763                 7                10                  37               0   \n905                  7                 6                  43               0   \n3980                 1                 6                  37               0   \n235                  7                 2                  72               0   \n\n      num_medications  prior_outpatient  ...  prior_inpatient  \\\n1621               11                 0  ...                0   \n902                10                 0  ...                0   \n3728               10                 0  ...                1   \n701                19                 0  ...                2   \n3776               18                 0  ...                0   \n...               ...               ...  ...              ...   \n2895               22                 0  ...                0   \n2763               10                 0  ...                0   \n905                 7                 0  ...                3   \n3980               14                 0  ...                0   \n235                 8                 0  ...                0   \n\n      primary_diagnosis number_diagnoses  max_glu_serum A1Cresult insulin  \\\n1621              Other                9           None      None      No   \n902            Diabetes                5           None      None      No   \n3728              Other                9           None      None  Steady   \n701               Other                6           None      None    Down   \n3776              Other                9           None      Norm      No   \n...                 ...              ...            ...       ...     ...   \n2895              Other                9           None      None      No   \n2763              Other                5           None      None      No   \n905            Diabetes                5           Norm      None    Down   \n3980              Other                6           None      None      No   \n235            Diabetes                3           None        >8  Steady   \n\n     diabetes_Med_prescribe  readmit_status medicare  medicaid  \n1621                     No  Not readmitted     True     False  \n902                     Yes  Not readmitted    False     False  \n3728                    Yes      Readmitted     True     False  \n701                     Yes  Not readmitted    False     False  \n3776                     No  Not readmitted    False     False  \n...                     ...             ...      ...       ...  \n2895                    Yes  Not readmitted    False     False  \n2763                     No      Readmitted     True     False  \n905                     Yes      Readmitted    False     False  \n3980                     No  Not readmitted    False      True  \n235                     Yes  Not readmitted    False     False  \n\n[3479 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>race</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>discharge_destination</th>\n      <th>admission_source</th>\n      <th>time_in_hospital</th>\n      <th>num_lab_procedures</th>\n      <th>num_procedures</th>\n      <th>num_medications</th>\n      <th>prior_outpatient</th>\n      <th>...</th>\n      <th>prior_inpatient</th>\n      <th>primary_diagnosis</th>\n      <th>number_diagnoses</th>\n      <th>max_glu_serum</th>\n      <th>A1Cresult</th>\n      <th>insulin</th>\n      <th>diabetes_Med_prescribe</th>\n      <th>readmit_status</th>\n      <th>medicare</th>\n      <th>medicaid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1621</th>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>7</td>\n      <td>5</td>\n      <td>40</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>Other</td>\n      <td>9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Not readmitted</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>902</th>\n      <td>AfricanAmerican</td>\n      <td>Male</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>7</td>\n      <td>2</td>\n      <td>35</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>Diabetes</td>\n      <td>5</td>\n      <td>None</td>\n      <td>None</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3728</th>\n      <td>Caucasian</td>\n      <td>Male</td>\n      <td>Over 60 years</td>\n      <td>Other</td>\n      <td>7</td>\n      <td>3</td>\n      <td>46</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>Other</td>\n      <td>9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Steady</td>\n      <td>Yes</td>\n      <td>Readmitted</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>701</th>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>Over 60 years</td>\n      <td>Other</td>\n      <td>7</td>\n      <td>9</td>\n      <td>53</td>\n      <td>2</td>\n      <td>19</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>Other</td>\n      <td>6</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Down</td>\n      <td>Yes</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3776</th>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>Over 60 years</td>\n      <td>Other</td>\n      <td>1</td>\n      <td>9</td>\n      <td>82</td>\n      <td>3</td>\n      <td>18</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>Other</td>\n      <td>9</td>\n      <td>None</td>\n      <td>Norm</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2895</th>\n      <td>Caucasian</td>\n      <td>Male</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>1</td>\n      <td>2</td>\n      <td>20</td>\n      <td>1</td>\n      <td>22</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>Other</td>\n      <td>9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2763</th>\n      <td>Caucasian</td>\n      <td>Male</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>7</td>\n      <td>10</td>\n      <td>37</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>Other</td>\n      <td>5</td>\n      <td>None</td>\n      <td>None</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Readmitted</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>905</th>\n      <td>AfricanAmerican</td>\n      <td>Female</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>7</td>\n      <td>6</td>\n      <td>43</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>Diabetes</td>\n      <td>5</td>\n      <td>Norm</td>\n      <td>None</td>\n      <td>Down</td>\n      <td>Yes</td>\n      <td>Readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3980</th>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>1</td>\n      <td>6</td>\n      <td>37</td>\n      <td>0</td>\n      <td>14</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>Other</td>\n      <td>6</td>\n      <td>None</td>\n      <td>None</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>Caucasian</td>\n      <td>Male</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>7</td>\n      <td>2</td>\n      <td>72</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>Diabetes</td>\n      <td>3</td>\n      <td>None</td>\n      <td>&gt;8</td>\n      <td>Steady</td>\n      <td>Yes</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>3479 rows × 21 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636036341
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[target_column].value_counts())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Not readmitted    2862\nReadmitted         617\nName: readmit_status, dtype: int64\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636037198
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[target_column].value_counts())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Not readmitted    1212\nReadmitted         279\nName: readmit_status, dtype: int64\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636037711
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "                 race  gender            age discharge_destination  \\\n1621        Caucasian  Female  Over 60 years    Discharged to Home   \n902   AfricanAmerican    Male  Over 60 years    Discharged to Home   \n3728        Caucasian    Male  Over 60 years                 Other   \n701         Caucasian  Female  Over 60 years                 Other   \n3776        Caucasian  Female  Over 60 years                 Other   \n\n      admission_source  time_in_hospital  num_lab_procedures  num_procedures  \\\n1621                 7                 5                  40               0   \n902                  7                 2                  35               0   \n3728                 7                 3                  46               0   \n701                  7                 9                  53               2   \n3776                 1                 9                  82               3   \n\n      num_medications  prior_outpatient  ...  prior_inpatient  \\\n1621               11                 0  ...                0   \n902                10                 0  ...                0   \n3728               10                 0  ...                1   \n701                19                 0  ...                2   \n3776               18                 0  ...                0   \n\n      primary_diagnosis number_diagnoses  max_glu_serum A1Cresult insulin  \\\n1621              Other                9           None      None      No   \n902            Diabetes                5           None      None      No   \n3728              Other                9           None      None  Steady   \n701               Other                6           None      None    Down   \n3776              Other                9           None      Norm      No   \n\n     diabetes_Med_prescribe  readmit_status medicare  medicaid  \n1621                     No  Not readmitted     True     False  \n902                     Yes  Not readmitted    False     False  \n3728                    Yes      Readmitted     True     False  \n701                     Yes  Not readmitted    False     False  \n3776                     No  Not readmitted    False     False  \n\n[5 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>race</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>discharge_destination</th>\n      <th>admission_source</th>\n      <th>time_in_hospital</th>\n      <th>num_lab_procedures</th>\n      <th>num_procedures</th>\n      <th>num_medications</th>\n      <th>prior_outpatient</th>\n      <th>...</th>\n      <th>prior_inpatient</th>\n      <th>primary_diagnosis</th>\n      <th>number_diagnoses</th>\n      <th>max_glu_serum</th>\n      <th>A1Cresult</th>\n      <th>insulin</th>\n      <th>diabetes_Med_prescribe</th>\n      <th>readmit_status</th>\n      <th>medicare</th>\n      <th>medicaid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1621</th>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>7</td>\n      <td>5</td>\n      <td>40</td>\n      <td>0</td>\n      <td>11</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>Other</td>\n      <td>9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Not readmitted</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>902</th>\n      <td>AfricanAmerican</td>\n      <td>Male</td>\n      <td>Over 60 years</td>\n      <td>Discharged to Home</td>\n      <td>7</td>\n      <td>2</td>\n      <td>35</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>Diabetes</td>\n      <td>5</td>\n      <td>None</td>\n      <td>None</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3728</th>\n      <td>Caucasian</td>\n      <td>Male</td>\n      <td>Over 60 years</td>\n      <td>Other</td>\n      <td>7</td>\n      <td>3</td>\n      <td>46</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>Other</td>\n      <td>9</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Steady</td>\n      <td>Yes</td>\n      <td>Readmitted</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>701</th>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>Over 60 years</td>\n      <td>Other</td>\n      <td>7</td>\n      <td>9</td>\n      <td>53</td>\n      <td>2</td>\n      <td>19</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>Other</td>\n      <td>6</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Down</td>\n      <td>Yes</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3776</th>\n      <td>Caucasian</td>\n      <td>Female</td>\n      <td>Over 60 years</td>\n      <td>Other</td>\n      <td>1</td>\n      <td>9</td>\n      <td>82</td>\n      <td>3</td>\n      <td>18</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>Other</td>\n      <td>9</td>\n      <td>None</td>\n      <td>Norm</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Not readmitted</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636038127
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "\r\n",
        "training_dataset_filename = 'hospital_train_parquet'\r\n",
        "testing_dataset_filename = 'hospital_test_parquet'\r\n",
        "\r\n",
        "\r\n",
        "training_data = Data(\r\n",
        "    name=training_dataset_filename,\r\n",
        "    path='data/train_dataset.parquet',\r\n",
        "    type=AssetTypes.URI_FILE,\r\n",
        "    description=\"RAI hospital  train data\",  \r\n",
        ")\r\n",
        "\r\n",
        "tr_data = ml_client.data.create_or_update(training_data)\r\n",
        "\r\n",
        "testing_data = Data(\r\n",
        "    name=testing_dataset_filename,\r\n",
        "    path='data/test_dataset.parquet',\r\n",
        "    type=AssetTypes.URI_FILE,\r\n",
        "    description=\"RAI hospital  test data\",  \r\n",
        ")\r\n",
        "\r\n",
        "te_data = ml_client.data.create_or_update(testing_data)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r\u001b[32mUploading train_dataset.parquet\u001b[32m (< 1 MB): 0.00B [00:00, ?B/s]\r\u001b[32mUploading train_dataset.parquet\u001b[32m (< 1 MB): 100%|██████████| 59.2k/59.2k [00:00<00:00, 4.07MB/s]\n\u001b[39m\n\n\r\u001b[32mUploading test_dataset.parquet\u001b[32m (< 1 MB): 0.00B [00:00, ?B/s]\r\u001b[32mUploading test_dataset.parquet\u001b[32m (< 1 MB): 100%|██████████| 34.9k/34.9k [00:00<00:00, 2.17MB/s]\n\u001b[39m\n\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636038966
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "os.makedirs('component', exist_ok=True)\r\n",
        "os.makedirs('register_model_src', exist_ok=True)\r\n",
        "os.makedirs('environment', exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636039748
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env_docker_context = Environment(\r\n",
        "    build=BuildContext(path=\"environment\"),\r\n",
        "    name=\"aml_rai_environment\",\r\n",
        "    description=\"Environment created from a Docker context.\",\r\n",
        ")\r\n",
        "ml_client.environments.create_or_update(env_docker_context)\r\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "Environment({'is_anonymous': False, 'auto_increment_version': False, 'name': 'aml_rai_environment', 'description': 'Environment created from a Docker context.', 'tags': {}, 'properties': {}, 'id': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/demoRG/providers/Microsoft.MachineLearningServices/workspaces/aml-ws/environments/aml_rai_environment/versions/38', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/trainingcompute/code/Users/ruyakubu/responsibleaidashboard-loan-approval-model-classification', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f3ce836bb20>, 'serialize': <msrest.serialization.Serializer object at 0x7f3cd01613a0>, 'version': '38', 'latest_version': None, 'conda_file': None, 'image': None, 'build': <azure.ai.ml.entities._assets.environment.BuildContext object at 0x7f3ce836bbb0>, 'inference_config': None, 'os_type': 'Linux', 'arm_type': 'environment_version', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636040407
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile component/hospital_training.py\r\n",
        "\r\n",
        "\r\n",
        "from pathlib import Path\r\n",
        "import sys\r\n",
        "import os\r\n",
        "\r\n",
        "parent_dir =  os.path.dirname(os.getcwd())\r\n",
        " \r\n",
        "# setting path\r\n",
        "sys.path.append(parent_dir)\r\n",
        "\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import tempfile\r\n",
        "\r\n",
        "from azureml.core import Run\r\n",
        "\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.compose import make_column_selector as selector\r\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "    # setup arg parser\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "\r\n",
        "    # add arguments\r\n",
        "    parser.add_argument(\"--training_data\", type=str, help=\"Path to training data\")\r\n",
        "    parser.add_argument(\"--target_column_name\", type=str, help=\"Name of target column\")\r\n",
        "    parser.add_argument(\"--model_output\", type=str, help=\"Path of output model\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parser.parse_args()    \r\n",
        "\r\n",
        "    # return args\r\n",
        "    return args\r\n",
        "\r\n",
        "def get_categorical_index(categorical_fields):\r\n",
        "    cat_idx = []\r\n",
        "    for col, value in categorical_fields.iteritems():\r\n",
        "        if value.dtype == 'object':\r\n",
        "            cat_idx.append(categorical_fields.columns.get_loc(col))\r\n",
        "    print(\"col indices: \", cat_idx)  \r\n",
        "    return cat_idx    \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def main(args):\r\n",
        "    current_experiment = Run.get_context().experiment\r\n",
        "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\r\n",
        "    print(\"tracking_uri: {0}\".format(tracking_uri))\r\n",
        "    mlflow.set_tracking_uri(tracking_uri)\r\n",
        "    mlflow.set_experiment(current_experiment.name)\r\n",
        "\r\n",
        "    # Read in data\r\n",
        "    print(\"Reading data\")\r\n",
        "    all_training_data = pd.read_parquet(args.training_data)\r\n",
        "    target = all_training_data[args.target_column_name]\r\n",
        "    features = all_training_data.drop([args.target_column_name], axis = 1)  \r\n",
        "\r\n",
        "    #features['age'] = pd.Categorical(all_training_data['age'], categories=['30 years or younger', '30-60 years', 'Over 60 years'], ordered=True)\r\n",
        "\r\n",
        "    # Transform string data to numeric\r\n",
        "    numerical_selector = selector(dtype_include=np.number)\r\n",
        "    categorical_selector = selector(dtype_exclude=np.number)\r\n",
        "\r\n",
        "    numerical_columns = numerical_selector(features)\r\n",
        "    categorical_columns = categorical_selector(features)\r\n",
        "\r\n",
        "    categorial_encoder = OneHotEncoder(handle_unknown=\"ignore\")\r\n",
        "    numerical_encoder = StandardScaler()\r\n",
        "\r\n",
        "    preprocessor = ColumnTransformer([\r\n",
        "    ('categorical-encoder', categorial_encoder, categorical_columns),\r\n",
        "    ('standard_scaler', numerical_encoder, numerical_columns)])\r\n",
        "\r\n",
        "    categorical_indices = get_categorical_index(features)\r\n",
        "    #clf = make_pipeline(preprocessor, RandomForestClassifier())\r\n",
        "    clf = make_pipeline(preprocessor, LogisticRegression())\r\n",
        "    \r\n",
        "\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=1)\r\n",
        "\r\n",
        "    print(\"Training model...\") \r\n",
        "    \r\n",
        "    model = clf.fit(X_train, y_train)\r\n",
        " \r\n",
        "    # Saving model with mlflow - leave this section unchanged\r\n",
        "    model_dir =  \"./model_output\"\r\n",
        "    with tempfile.TemporaryDirectory() as td:\r\n",
        "        print(\"Saving model with MLFlow to temporary directory\")\r\n",
        "        tmp_output_dir = os.path.join(td, model_dir)\r\n",
        "        mlflow.sklearn.save_model(sk_model=model, path=tmp_output_dir)\r\n",
        "\r\n",
        "        print(\"Copying MLFlow model to output path\")\r\n",
        "        for file_name in os.listdir(tmp_output_dir):\r\n",
        "            print(\"  Copying: \", file_name)\r\n",
        "            # As of Python 3.8, copytree will acquire dirs_exist_ok as\r\n",
        "            # an option, removing the need for listdir\r\n",
        "            shutil.copy2(src=os.path.join(tmp_output_dir, file_name), dst=os.path.join(args.model_output, file_name))\r\n",
        "\r\n",
        "\r\n",
        "# run script\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parse_args()\r\n",
        "\r\n",
        "    # run main function\r\n",
        "    main(args)\r\n",
        "\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting component/hospital_training.py\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile register_model_src/model_register.py\r\n",
        "\r\n",
        "# ---------------------------------------------------------\r\n",
        "# Copyright (c) Microsoft Corporation. All rights reserved.\r\n",
        "# ---------------------------------------------------------\r\n",
        "\r\n",
        "import argparse\r\n",
        "import json\r\n",
        "import os\r\n",
        "import time\r\n",
        "\r\n",
        "\r\n",
        "from azureml.core import Run\r\n",
        "\r\n",
        "import mlflow\r\n",
        "import mlflow.sklearn\r\n",
        "\r\n",
        "# Based on example:\r\n",
        "# https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-cli\r\n",
        "# which references\r\n",
        "# https://github.com/Azure/azureml-examples/tree/main/cli/jobs/train/lightgbm/iris\r\n",
        "\r\n",
        "\r\n",
        "def parse_args():\r\n",
        "    # setup arg parser\r\n",
        "    parser = argparse.ArgumentParser()\r\n",
        "\r\n",
        "    # add arguments\r\n",
        "    parser.add_argument(\"--model_input_path\", type=str, help=\"Path to input model\")\r\n",
        "    parser.add_argument(\r\n",
        "        \"--model_info_output_path\", type=str, help=\"Path to write model info JSON\"\r\n",
        "    )\r\n",
        "    parser.add_argument(\r\n",
        "        \"--model_base_name\", type=str, help=\"Name of the registered model\"\r\n",
        "    )\r\n",
        "    parser.add_argument(\r\n",
        "        \"--model_name_suffix\", type=int, help=\"Set negative to use epoch_secs\"\r\n",
        "    )\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parser.parse_args()\r\n",
        "\r\n",
        "    # return args\r\n",
        "    return args\r\n",
        "\r\n",
        "\r\n",
        "def main(args):\r\n",
        "    current_experiment = Run.get_context().experiment\r\n",
        "    tracking_uri = current_experiment.workspace.get_mlflow_tracking_uri()\r\n",
        "    print(\"tracking_uri: {0}\".format(tracking_uri))\r\n",
        "    mlflow.set_tracking_uri(tracking_uri)\r\n",
        "    mlflow.set_experiment(current_experiment.name)\r\n",
        "\r\n",
        "    print(\"Loading model\")\r\n",
        "    mlflow_model = mlflow.sklearn.load_model(args.model_input_path)\r\n",
        "\r\n",
        "    if args.model_name_suffix < 0:\r\n",
        "        suffix = int(time.time())\r\n",
        "    else:\r\n",
        "        suffix = args.model_name_suffix\r\n",
        "    registered_name = \"{0}_{1}\".format(args.model_base_name, suffix)\r\n",
        "    print(f\"Registering model as {registered_name}\")\r\n",
        "\r\n",
        "    print(\"Registering via MLFlow\")\r\n",
        "    mlflow.sklearn.log_model(\r\n",
        "        sk_model=mlflow_model,\r\n",
        "        registered_model_name=registered_name,\r\n",
        "        artifact_path=registered_name,\r\n",
        "    )\r\n",
        "\r\n",
        "    print(\"Writing JSON\")\r\n",
        "    dict = {\"id\": \"{0}:1\".format(registered_name)}\r\n",
        "    output_path = os.path.join(args.model_info_output_path, \"model_info.json\")\r\n",
        "    with open(output_path, \"w\") as of:\r\n",
        "        json.dump(dict, fp=of)\r\n",
        "\r\n",
        "\r\n",
        "# run script\r\n",
        "if __name__ == \"__main__\":\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")\r\n",
        "\r\n",
        "    # parse args\r\n",
        "    args = parse_args()\r\n",
        "\r\n",
        "    # run main function\r\n",
        "    main(args)\r\n",
        "\r\n",
        "    # add space in logs\r\n",
        "    print(\"*\" * 60)\r\n",
        "    print(\"\\n\\n\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting register_model_src/model_register.py\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import load_component\n",
        "\n",
        "yaml_contents = f\"\"\"\n",
        "$schema: http://azureml/sdk-2-0/CommandComponent.json\n",
        "name: rai_hospital_training_component\n",
        "display_name: hospital  classification training component for RAI example\n",
        "version: {rai_hospital_classifier_version_string}\n",
        "type: command\n",
        "inputs:\n",
        "  training_data:\n",
        "    type: path\n",
        "  target_column_name:\n",
        "    type: string\n",
        "outputs:\n",
        "  model_output:\n",
        "    type: path\n",
        "code: ./component/\n",
        "environment: azureml://registries/azureml/environments/AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu/versions/4\n",
        "\"\"\" + r\"\"\"\n",
        "command: >-\n",
        "  python hospital_training.py\n",
        "  --training_data ${{{{inputs.training_data}}}}\n",
        "  --target_column_name ${{{{inputs.target_column_name}}}}\n",
        "  --model_output ${{{{outputs.model_output}}}}\n",
        "\"\"\"\n",
        "\n",
        "yaml_filename = \"RAIhospitalClassificationTrainingComponent.yaml\"\n",
        "\n",
        "with open(yaml_filename, 'w') as f:\n",
        "    f.write(yaml_contents.format(yaml_contents))\n",
        "    \n",
        "train_component_definition = load_component(\n",
        "    source=yaml_filename\n",
        ")\n",
        "\n",
        "ml_client.components.create_or_update(train_component_definition)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "CommandComponent({'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'name': 'rai_hospital_training_component', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/demoRG/providers/Microsoft.MachineLearningServices/workspaces/aml-ws/components/rai_hospital_training_component/versions/134', 'Resource__source_path': None, 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f3cd010b0a0>, 'serialize': <msrest.serialization.Serializer object at 0x7f3cd0172cd0>, 'command': 'python hospital_training.py --training_data ${{inputs.training_data}} --target_column_name ${{inputs.target_column_name}} --model_output ${{outputs.model_output}}', 'code': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/demoRG/providers/Microsoft.MachineLearningServices/workspaces/aml-ws/codes/b1f822d6-2eaf-4fbb-a0d6-ebba570fb592/versions/1', 'environment_variables': None, 'environment': 'azureml://registries/azureml/environments/AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu/versions/4', 'distribution': None, 'resources': {'instance_count': 1, 'properties': {}}, 'version': '134', 'latest_version': None, 'schema': 'http://azureml/sdk-2-0/CommandComponent.json', 'type': 'command', 'display_name': 'hospital  classification training component for RAI example', 'is_deterministic': True, 'inputs': {'training_data': {'type': 'path'}, 'target_column_name': {'type': 'string'}}, 'outputs': {'model_output': {'type': 'path'}}, 'yaml_str': None, 'other_parameter': {}, 'func': <function [component] hospital  classification training component for RAI example at 0x7f3cd012cee0>})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1675636042314
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_contents = f\"\"\"\r\n",
        "$schema: http://azureml/sdk-2-0/CommandComponent.json\r\n",
        "name: register_hospital_model\r\n",
        "display_name: Register hospital Model\r\n",
        "version: {rai_hospital_classifier_version_string}\r\n",
        "type: command\r\n",
        "is_deterministic: False\r\n",
        "inputs:\r\n",
        "  model_input_path:\r\n",
        "    type: path\r\n",
        "  model_base_name:\r\n",
        "    type: string\r\n",
        "  model_name_suffix: # Set negative to use epoch_secs\r\n",
        "    type: integer\r\n",
        "    default: -1\r\n",
        "outputs:\r\n",
        "  model_info_output_path:\r\n",
        "    type: path\r\n",
        "code: ./register_model_src/\r\n",
        "environment: azureml://registries/azureml/environments/AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu/versions/4\r\n",
        "command: >-\r\n",
        "  python model_register.py\r\n",
        "  --model_input_path ${{{{inputs.model_input_path}}}}\r\n",
        "  --model_base_name ${{{{inputs.model_base_name}}}}\r\n",
        "  --model_name_suffix ${{{{inputs.model_name_suffix}}}}\r\n",
        "  --model_info_output_path ${{{{outputs.model_info_output_path}}}}\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "yaml_filename = \"model_register.yaml\"\r\n",
        "\r\n",
        "with open(yaml_filename, 'w') as f:\r\n",
        "    f.write(yaml_contents)\r\n",
        "    \r\n",
        "register_component = load_component(\r\n",
        "    source=yaml_filename\r\n",
        ")\r\n",
        "\r\n",
        "ml_client.components.create_or_update(register_component)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "CommandComponent({'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.COMPONENT', 'is_anonymous': False, 'name': 'register_hospital_model', 'description': None, 'tags': {}, 'properties': {}, 'id': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/demoRG/providers/Microsoft.MachineLearningServices/workspaces/aml-ws/components/register_hospital_model/versions/134', 'Resource__source_path': None, 'base_path': './', 'creation_context': <azure.ai.ml._restclient.v2022_05_01.models._models_py3.SystemData object at 0x7f3cd00b3910>, 'serialize': <msrest.serialization.Serializer object at 0x7f3cd00401f0>, 'command': 'python model_register.py --model_input_path ${{inputs.model_input_path}} --model_base_name ${{inputs.model_base_name}} --model_name_suffix ${{inputs.model_name_suffix}} --model_info_output_path ${{outputs.model_info_output_path}}', 'code': '/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourceGroups/demoRG/providers/Microsoft.MachineLearningServices/workspaces/aml-ws/codes/8453ff98-e386-4fe1-9177-9133162c5bc4/versions/1', 'environment_variables': None, 'environment': 'azureml://registries/azureml/environments/AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu/versions/4', 'distribution': None, 'resources': {'instance_count': 1, 'properties': {}}, 'version': '134', 'latest_version': None, 'schema': 'http://azureml/sdk-2-0/CommandComponent.json', 'type': 'command', 'display_name': 'Register hospital Model', 'is_deterministic': False, 'inputs': {'model_input_path': {'type': 'path'}, 'model_base_name': {'type': 'string'}, 'model_name_suffix': {'type': 'integer', 'default': -1}}, 'outputs': {'model_info_output_path': {'type': 'path'}}, 'yaml_str': None, 'other_parameter': {}, 'func': <function [component] Register hospital Model at 0x7f3cd012c820>})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636043017
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\r\n",
        "\r\n",
        "model_name_suffix = int(time.time())\r\n",
        "model_base_name = 'rai_hospital_model'"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636043509
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl, Input\r\n",
        "\r\n",
        "\r\n",
        "hospital_train_parquet = Input(\r\n",
        "    type=\"uri_file\", path=\"data/train_dataset.parquet\", mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "hospital_test_parquet = Input(\r\n",
        "    type=\"uri_file\", path=\"data/test_dataset.parquet\", mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "@dsl.pipeline(\r\n",
        "    compute=compute_name,\r\n",
        "    description=\"Register Model for RAI hospital \",\r\n",
        "    experiment_name=f\"RAI_hospital_Model_Training_{model_name_suffix}\",\r\n",
        ")\r\n",
        "def my_training_pipeline(target_column_name, training_data):\r\n",
        "    trained_model = train_component_definition(\r\n",
        "        target_column_name=target_column_name,\r\n",
        "        training_data=training_data\r\n",
        "    )\r\n",
        "    trained_model.set_limits(timeout=120)\r\n",
        "\r\n",
        "    _ = register_component(\r\n",
        "        model_input_path=trained_model.outputs.model_output,\r\n",
        "        model_base_name=model_base_name,\r\n",
        "        model_name_suffix=model_name_suffix,\r\n",
        "    )\r\n",
        "\r\n",
        "    return {}\r\n",
        "\r\n",
        "model_registration_pipeline_job = my_training_pipeline(target_column, hospital_train_parquet)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636043869
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import PipelineJob\r\n",
        "import webbrowser\r\n",
        "\r\n",
        "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\r\n",
        "    created_job = ml_client.jobs.create_or_update(pipeline_job)\r\n",
        "    assert created_job is not None\r\n",
        "\r\n",
        "    while created_job.status not in ['Completed', 'Failed', 'Canceled', 'NotResponding']:\r\n",
        "        time.sleep(30)\r\n",
        "        created_job = ml_client.jobs.get(created_job.name)\r\n",
        "        print(\"Latest status : {0}\".format(created_job.status))\r\n",
        "\r\n",
        "\r\n",
        "    # open the pipeline in web browser\r\n",
        "    webbrowser.open(created_job.services[\"Studio\"].endpoint)\r\n",
        "    \r\n",
        "    #assert created_job.status == 'Completed'\r\n",
        "    return created_job\r\n",
        "\r\n",
        "# This is the actual submission\r\n",
        "training_job = submit_and_wait(ml_client, model_registration_pipeline_job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Latest status : Running\nLatest status : Completed\n"
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636114148
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expected_model_id = f'{model_base_name}_{model_name_suffix}:1'\r\n",
        "azureml_model_id = f'azureml:{expected_model_id}'"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636114736
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_categorical_numerical_data(dataset):\r\n",
        "    dataset = dataset.drop([target_column], axis = 1)  \r\n",
        "    categorical = []\r\n",
        "    for col, value in dataset.iteritems():\r\n",
        "        if value.dtype == 'object' or value.dtype == 'bool':\r\n",
        "            categorical.append(col)\r\n",
        "    numerical = dataset.columns.difference(categorical)\r\n",
        "    return categorical, numerical"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636115154
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get categorical and numerical fields from training data\r\n",
        "categorical, numerical = get_categorical_numerical_data(train_data)\r\n",
        "print(\"categorical columns: \",  categorical)\r\n",
        "print(\"numerical field: \", numerical)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "categorical columns:  ['race', 'gender', 'age', 'discharge_destination', 'primary_diagnosis', 'max_glu_serum', 'A1Cresult', 'insulin', 'diabetes_Med_prescribe', 'medicare', 'medicaid']\nnumerical field:  Index(['admission_source', 'num_lab_procedures', 'num_medications',\n       'num_procedures', 'number_diagnoses', 'prior_emergency',\n       'prior_inpatient', 'prior_outpatient', 'time_in_hospital'],\n      dtype='object')\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636115468
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = \"latest\"\r\n",
        "\r\n",
        "rai_constructor_component = ml_client_registry.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=label\r\n",
        ")\r\n",
        "\r\n",
        "# We get latest version and use the same version for all components\r\n",
        "version = rai_constructor_component.version\r\n",
        "\r\n",
        "rai_counterfactual_component = ml_client_registry.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_counterfactual\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_causal_component = ml_client_registry.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_causal\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_explanation_component = ml_client_registry.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_explanation\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_erroranalysis_component = ml_client_registry.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_erroranalysis\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_gather_component = ml_client_registry.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_insight_gather\", version=version\r\n",
        ")\r\n",
        "\r\n",
        "rai_scorecard_component = ml_client_registry.components.get(\r\n",
        "    name=\"microsoft_azureml_rai_tabular_score_card\", version=version\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636115882
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "score_card_config_dict = {\r\n",
        "    \"Model\": {\r\n",
        "        \"ModelName\": \"Diabetes hospital readmission\",\r\n",
        "        \"ModelType\": \"Classification\",\r\n",
        "        \"ModelSummary\": \"This model predicts whether a diabetic patient will be readmitted back to hospital within 30 days\"\r\n",
        "    },\r\n",
        "    \"Metrics\" :{\r\n",
        "        \"accuracy_score\": {\r\n",
        "            \"threshold\": \">=0.80\"\r\n",
        "        },\r\n",
        "        \"precision_score\": {}\r\n",
        "    },\r\n",
        "    \"FeatureImportance\": { \r\n",
        "        \"top_n\": 10 \r\n",
        "    }, \r\n",
        "    \"DataExplorer\": { \r\n",
        "        \"features\": [ \r\n",
        "        \"time_in_hospital\", \r\n",
        "        \"prior_inpatient\", \r\n",
        "        \"age\"\r\n",
        "        ] \r\n",
        "    },\r\n",
        "    \"Fairness\": { \r\n",
        "        \"metric\": [\"accuracy_score\"], \r\n",
        "        \"sensitive_features\": [\"age\", \"race\", \"gender\"],\r\n",
        "        \"fairness_evaluation_kind\": \"ratio\"\r\n",
        "    }\r\n",
        "}\r\n",
        "\r\n",
        "score_card_config_filename = \"rai_hospital_readmission_score_card_config.json\"\r\n",
        "\r\n",
        "with open(score_card_config_filename, 'w') as f:\r\n",
        "    json.dump(score_card_config_dict, f)"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636116583
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "\r\n",
        "score_card_config_path = Input(\r\n",
        "    type=\"uri_file\",\r\n",
        "    path=score_card_config_filename,\r\n",
        "    mode=\"download\"\r\n",
        ")\r\n",
        "\r\n",
        "@dsl.pipeline(\r\n",
        "        compute=compute_name,\r\n",
        "        description=\"RAI computation on hospital readmit classification data\",\r\n",
        "        experiment_name=f\"RAI_hospital_Classification_RAIInsights_Computation_{model_name_suffix}\",\r\n",
        "    )\r\n",
        "def rai_classification_pipeline(\r\n",
        "        target_column_name,\r\n",
        "        training_data,\r\n",
        "        testing_data,\r\n",
        "        score_card_config_path\r\n",
        "    ):\r\n",
        "        \r\n",
        "        # Initiate the RAIInsights\r\n",
        "        create_rai_job = rai_constructor_component(\r\n",
        "            title=\"RAI Dashboard\",\r\n",
        "            task_type=\"classification\",\r\n",
        "            model_info=expected_model_id,\r\n",
        "            model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),            \r\n",
        "            train_dataset=training_data,\r\n",
        "            test_dataset=testing_data,\r\n",
        "            target_column_name=target_column_name,\r\n",
        "            #classes=json.dumps(['not readmitted', 'readmitted']),\r\n",
        "            categorical_column_names=json.dumps(categorical),\r\n",
        "        )\r\n",
        "        create_rai_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "        # Add an explanation\r\n",
        "        explain_job = rai_explanation_component(\r\n",
        "            comment=\"Explanation for hospital remitted less than 30days  classification\",\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        explain_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "        # Add error analysis\r\n",
        "        erroranalysis_job = rai_erroranalysis_component(\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        erroranalysis_job.set_limits(timeout=120)\r\n",
        "\r\n",
        "        # Add counterfactual analysis\r\n",
        "        counterfactual_job = rai_counterfactual_component(\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "            total_cfs=10,\r\n",
        "            desired_class='opposite',\r\n",
        "        )\r\n",
        "        counterfactual_job.set_limits(timeout=600)\r\n",
        "\r\n",
        "        # Add causal analysis\r\n",
        "        causal_job = rai_causal_component(\r\n",
        "            treatment_features=json.dumps(['time_in_hospital']),\r\n",
        "            rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "        )\r\n",
        "        causal_job.set_limits(timeout=120)\r\n",
        "        \r\n",
        "\r\n",
        "        # Combine everything\r\n",
        "        rai_gather_job = rai_gather_component(\r\n",
        "            constructor=create_rai_job.outputs.rai_insights_dashboard,\r\n",
        "            insight_1=explain_job.outputs.explanation,\r\n",
        "            insight_2=causal_job.outputs.causal,\r\n",
        "            insight_3=counterfactual_job.outputs.counterfactual,\r\n",
        "            insight_4=erroranalysis_job.outputs.error_analysis,\r\n",
        "        )\r\n",
        "        rai_gather_job.set_limits(timeout=120)\r\n",
        "\r\n",
        "        rai_gather_job.outputs.dashboard.mode = \"upload\"\r\n",
        "        rai_gather_job.outputs.ux_json.mode = \"upload\"\r\n",
        "\r\n",
        "        # Generate score card in pdf format for a summary report on model performance,\r\n",
        "        # and observe distrbution of error between prediction vs ground truth.\r\n",
        "        rai_scorecard_job = rai_scorecard_component(\r\n",
        "            dashboard=rai_gather_job.outputs.dashboard,\r\n",
        "            pdf_generation_config=score_card_config_path\r\n",
        "        )\r\n",
        "\r\n",
        "        return {\r\n",
        "            \"dashboard\": rai_gather_job.outputs.dashboard,\r\n",
        "            \"ux_json\": rai_gather_job.outputs.ux_json,\r\n",
        "            \"scorecard\": rai_scorecard_job.outputs.scorecard\r\n",
        "        }"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636116998
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\r\n",
        "from azure.ai.ml import Output\r\n",
        "\r\n",
        "# Pipeline to construct the RAI Insights\r\n",
        "insights_pipeline_job = rai_classification_pipeline(\r\n",
        "    target_column_name=target_column,\r\n",
        "    training_data=hospital_train_parquet,\r\n",
        "    testing_data=hospital_test_parquet,\r\n",
        "    score_card_config_path=score_card_config_path,\r\n",
        ")\r\n",
        "\r\n",
        "# Workaround to enable the download\r\n",
        "rand_path = str(uuid.uuid4())\r\n",
        "insights_pipeline_job.outputs.dashboard = Output(\r\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\r\n",
        "    mode=\"upload\",\r\n",
        "    type=\"uri_folder\",\r\n",
        ")\r\n",
        "insights_pipeline_job.outputs.ux_json = Output(\r\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/ux_json/\",\r\n",
        "    mode=\"upload\",\r\n",
        "    type=\"uri_folder\",\r\n",
        ")\r\n",
        "insights_pipeline_job.outputs.scorecard = Output(\r\n",
        "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/scorecard/\",\r\n",
        "    mode=\"upload\",\r\n",
        "    type=\"uri_folder\",\r\n",
        ")\r\n",
        "\r\n",
        "# submit pipeline\r\n",
        "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Latest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Running\nLatest status : Failed\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636723876
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_id = ml_client._operation_scope.subscription_id\r\n",
        "rg_name = ml_client._operation_scope.resource_group_name\r\n",
        "ws_name = ml_client.workspace_name\r\n",
        "\r\n",
        "expected_uri = f\"https://ml.azure.com/model/{expected_model_id}/model_analysis?wsid=/subscriptions/{sub_id}/resourcegroups/{rg_name}/workspaces/{ws_name}\"\r\n",
        "\r\n",
        "print(f\"Please visit {expected_uri} to see your analysis\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Please visit https://ml.azure.com/model/rai_hospital_model_1675636042:1/model_analysis?wsid=/subscriptions/8a0f6419-1f4c-45b3-8d92-ee53be1ea443/resourcegroups/demoRG/workspaces/aml-ws to see your analysis\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1675636724384
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}